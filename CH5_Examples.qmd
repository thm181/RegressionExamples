---
title: "Correlation & Regression:"
subtitle: "Chapter 5 & 6 Examples"
author: "THM"
format: 
  html:
    embed-resources: true
    toc: true
    code-tools: true

csl: ecology.csl
editor: visual
bibliography: references.bib
---

```{r}
#| label: SetUp
#| message: FALSE
#| echo: FALSE

knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
  ) 

library(ggfortify)
library(glue)
library(GGally)
library(car)
library(patchwork)
library(broom)
library(latex2exp)       
library(kableExtra)
library(tidyverse)

options(knitr.kable.NA = '')
```

<!--# This chunk is a work-around to allow left-aligned table captions -->

```{=html}
<style type="text/css">
caption, .table-caption {
  text-align: left;
}
</style>
```
## Box 5.1 \| crab and burrow density on Christmas Island

@Quinn.Keough2002 used a subset of the data on Christmas Island red land crabs generated by @Green1997 to demonstrate the correlation between total biomass and burrow density within 25 $m^2$ quadrats at Green's Lower Site (*LS*, 10 quadrats) and Drum Site (*DS*, 8 quadrats).

```{r }
#| label: greenImport
green <- read_csv("green.csv", show_col_types = FALSE)

```

@Quinn.Keough2002 generate three measures of correlation: Pearson's correlation coefficient, *r* (= Pearson's Product Moment), the parametric measure of covariance standardized by dividing by the standard deviations of the two variables, Spearman's rank correlation coefficient, $\rho$, merely the Pearson correlation of the ranked data, and Kendall's rank correlation, $\tau$.

Kendall's $\tau$ is calculated as:

$$\tau = \frac{(number~of~concordant~pairs) - (number~of~discordant ~pairs)}{n(n-1)/2}$$ where concordant pairs are those pairs that are in the same rank (= same sort order) and discordant pairs are those where the ranks do not match.

The tests of significance for these measures are t-test for the parametric Pearson's correlation and sometimes for Spearman's rank correlation, though with modern computing power, a permutation test is used more often for the non-parametric rank tests if there are no ties. If there are ties, the tests are based on approximate *t* or *normal* distributions.

We can use cor.test() from base R [@base] to compute the correlations and perform the statistical tests. I have extracted the various measures and constructed a table in the code chunk below (@tbl-corTests).

```{r }
#| label: tbl-corTests
#| tbl-cap: "Measures of correlation and statistical tests between total biomass of red land crabs and number of burrows."
#| warning: false

LS <- subset(green, SITE == "LS")
DS <- subset(green, SITE == "DS")

out.LS.r <- cor.test(LS$TOTMASS, LS$BURROWS, method = "pearson")

out.LS.rho <- cor.test(LS$TOTMASS, LS$BURROWS, method = "spearman", exact = TRUE)

out.LS.tau <- cor.test(LS$TOTMASS, LS$BURROWS, method = "kendall", exact = TRUE)

out.DS.r <- cor.test(DS$TOTMASS, DS$BURROWS, method = "pearson")

out.DS.rho <- cor.test(DS$TOTMASS, DS$BURROWS, method = "spearman", exact = TRUE)

out.DS.tau <- cor.test(DS$TOTMASS, DS$BURROWS, method = "kendall", exact = TRUE)

col1 <- c("DS (n = 8)", "", "", "LS (n = 10)", "", "")
col2 <- c("Pearson", "Spearman", "Kendall", "Pearson", "Spearman", "Kendall")
col3 <- round(c(out.DS.r$estimate, out.DS.rho$estimate, out.DS.tau$estimate,
          out.LS.r$estimate, out.LS.rho$estimate, out.LS.tau$estimate), 3)
col4 <- round(
  c(
    out.DS.r$p.value, 
    out.DS.rho$p.value, 
    out.DS.tau$p.value,
    out.LS.r$p.value, 
    out.LS.rho$p.value, 
    out.LS.tau$p.value
    ),
  3
  )

corTable <- cbind(
  col1, 
  col2, 
  col3, 
  col4
  )
   
row.names(corTable) <- NULL

kbl(
  corTable, 
  justify = "llrr", 
  col.names = c("Site", "Correlation type", "Statistic", "P value"),
  digits = c(0,0,3,3)
    ) |>
  kable_classic(full = FALSE)

```

```{r }
#| label: fig-greenPlot
#| fig.cap: "Scatterplots showing the relationship between number of burrows of red land crabs and total crab biomass in 25 $m^2$ quadrats at two sites (LS, DS) on Christmas Island [@Green1997]."

mod.LS <- lm(TOTMASS ~ BURROWS, LS)

LS.scatter <- ggplot(LS, aes(TOTMASS, BURROWS)) +
  geom_point(shape = 19, size = 5, alpha = 0.5) +
  geom_smooth(method = lm, se = FALSE) +
  scale_x_continuous("Total Biomass (kg)", limits = c(0,5), expand = c(0,0)) +
  scale_y_continuous("Number of Burrows", limits = c(0,85), expand = c(0,0)) +
  theme_classic()

mod.DS <- lm(TOTMASS ~ BURROWS, DS)

DS.scatter <- ggplot(DS, aes(TOTMASS, BURROWS)) +
  geom_smooth(method = lm, se = FALSE) +
  geom_point(shape = 19, size = 5, alpha = 0.5) +
  scale_x_continuous("Total Biomass (kg)", limits = c(0,5), expand = c(0,0)) +
  scale_y_continuous("Number of Burrows", limits = c(0,85), expand = c(0,0)) +
  theme_classic()

LS.scatter + DS.scatter +
  plot_annotation(tag_levels = "a")
```

## Box 6.1 \| Worked example of multiple linear regression: relative abundance of plant functional types

@Paruelo.Lauenroth1996 analyzed the geographic distribution and the effects of climate variables on the relative abundance of a number of plant functional types including shrubs, forbs, succulents (e.g. cacti), C3 grasses and C4 grasses. There were 73 sites across North America. The variables of interest[^1] for this example were:

-   the relative abundance of C3 plants (`c3`),
-   the relative abundance of C4 plants (`c4`),
-   the latitude in centesimal degrees[^2] (`lat`),
-   the longitude in centesimal degrees (`long`),
-   the mean annual precipitation in mm (`map`),
-   the mean annual temperature in $^\circ C$ (`mat`),
-   the proportion of `map` that fell in June, July and August (`jjamap`), and
-   the proportion of `map` that fell in December, January and February (`djfmap`).

```{r }
#| label: tbl-parueloData
#| tbl-cap: "First six observations from Paruelo and Lauenroth's data."

df <- read_csv("paruelo.csv", show_col_types = FALSE)
names(df) <- tolower(names(df))

kbl(
  head(df)
  ) |>
  kable_classic()

```

## The data.

@Quinn.Keough2002 produced a table of pairwise correlation coefficients. I have chosen to use `GGally::ggpairs()` [@GGally]to generate a *scatterplot matrix* that includes the correlation coefficients (@fig-corrMat). This function offers options ([See the help file](https://www.rdocumentation.org/packages/GGally/versions/1.3.2/topics/ggpairs)) to provide much more information than just the correlation coefficients in the same amount of space. I have the correlation coefficients in the upper triangle, the distributions on the diagonal, and pair-wise scatterplots in the lower triangle. Note that the correlation coefficients are for the pair of variables denoted by the column and row labels, the distributions are for the variable denoted by the column or row label, and the x-axis of the scatterplots is the column label while the y-axis is the row label. There are a number of approaches to producing tables or figures summarizing pair-wise correlation coefficients in R. Try searching for "R correlation table" in your favorite search engine.

```{r }
#| label: fig-corrMat
#| fig.cap: "A matrix of pair-wise scatterplots, variable distribution, and correlation coefficients for all variables provided in the @Paruelo.Lauenroth1996 data file. Asterisks indicate statistically significant correlations."
ggpairs(df, diag = list(continous = "densityDiag"),
        axisLabels = "show",
        lower = list(continuous = wrap("points", 
                                       alpha = 0.3, 
                                       size = 0.5)),
        progress = FALSE) +
  theme(axis.text.x = element_blank()) +
  theme_bw()
```

Note the strong correlations (usually considered to be r \> 0.70) between some variables. These strong correlations among pairs of predictor variables suggest potential problems with collinearity.

## Building a model

@Quinn.Keough2002 focus on the relative abundance of C3 plants. Note that C3 has positive skew (@fig-corrMat); a log(x) transform can "normalize" the distribution. However, there are zeros, so the authors used $log_{10}(C3+0.1)$.

The first model they try is a simple linear model with no interactions. Note that with 6 predictor variables, there are a total of 64 model terms possible if all interactions are included.

$$log_{10}(c3 + 0.1) = \beta_0 + \beta_1(lat) + \beta_2(long) + \beta_3(map) + \beta_4(mat) + \beta_5(jjamap) + \beta_6(djfmap) + \epsilon$$

In R, we fit multiple regression (= multiple correlation) models in the same way we fit simple linear regression models; we use the `lm()` function. We can measure multicollinearity among predictor variables using a measure known as the "variance inflation factor"[^3]:

$$VIF_i = \frac{1}{1-r^2_i}$$

Where $r_i^2$, the coefficient of determination, is from the regression of variable $i$ against all of the other predictor variables. The square root of the variance inflation factor $(\sqrt{VIF})$ indicates how much larger the standard error of the model is with the predictor variable correlated with other variables relative to what it would be if the variables were not correlated. For example, `long` has a VIF of 5.3 (@tbl-fullMod), this suggests that the standard error of the model is $\sqrt{5.3}=`r round(sqrt(5.3), 1)` X$ larger because of the multicollinearity of `long` with the other variables.

There isn't a significance test that we can use to help inform our decision about multicollinearity, but many experienced statisticians have offered their opinion for "rules-of-thumb." Most have argued that a VIF of 5 warrants serious consideration and that a VIF of 10 indicates serious multicollinearity. However, others consider a VIF as low as 2 to be an indication of too much. All of our predictor variables have VIF values greater than 2, and `long` and `djfmap` have VIFs above 5 (@tbl-fullMod).

```{r fullMod}
#| label: tbl-fullMod
#| tbl-cap: "Regression summary and VIF for the full model using all six predictive variables."
             
full.mod <- lm(log10(c3+0.1) ~ lat + long + map + mat + jjamap + djfmap, 
               data = df)

out = round(glance(full.mod), 2)
footy1 <- glue("$r^2 = $ {out$r.squared}")

# Create a data.frame with the information we want in a "prettified" summary
# table. The output from "summary()$coefficients" has columns, in order:
# variable name, estimate, standard error, t statistic, P-value for the t
# statistic. We can then use cbind() to add a column of the variance inflation
# factors, vif().

# The tbl_regression() function from the gtsummary package can do this
# automatically in a couple of lines of code, but to get the same number format
# requires adding even more lines of code, so I'm sticking with kableExtra for
# now.

tab <- data.frame(
  cbind(
    summary(full.mod)$coefficients,
    # adds "NA" as the first row (after the 0 row) for the intercept
    append(vif(full.mod), values = NA, after = 0) 
    )
  ) 

# Create a column that contains the "row names" that lm() uses for the
# matrix-like output from summary()$coefficients.

tab <- rownames_to_column(tab, var = "Variable")

# Code to replace very small P-values with "<0.001" -- the syntax for the
# ifelse() function is ifelse(<logical test>, <value if true>, <value if
# false>). It is a very handy function to know. 

# Note that format() changes numeric variables to character variables, as does
# substituting "< 0.001".

tab$Pr...t.. <- ifelse(tab$Pr...t.. < 0.001, "< 0.001", 
                       format(
                         round(
                           tab$Pr...t..,
                           digits = 3
                           ),
                         nsmall = 3
                         )
                       )


fullMod <- kbl(
  tab,
  col.names = c(
    " ",
    "$\\hat{\\beta}$",
    "SE",
    "t-statistic",
    "P-value",
    "VIF"
  ),
  digits = c(0, 2, 2, 2, 0, 1),
  align = "lrrrrr"
  ) |>
  kable_classic(full = FALSE)

fullMod  
```

The resulting model fits the data pretty well, adjusted $r^2=$ `r round(summary(full.mod)$adj.r.squared, 2)`, and the coefficient for latitude appears to be significantly different from zero ((@tbl-fullMod)). The residuals appear to be relatively normally distributed (@fig-diagPlotfull) and to fit the linear model. Residual variance appears to rise at intermediate magnitudes of the fitted values, but there is no consistent up or down trend.

```{r }
#| label: fig-diagPlotfull
#| fig.cap: "Diagnostic plots for the model containing all six predictive variables."

autoplot(full.mod) + 
  theme_classic()
```

# Further diagnostics and interpretation: Added Variable Plots:

Added-variable plots, also called "partial regression plots," "adjusted variable plots," or "individual coefficient plots," is a graphical technique to explore the effect of adding an additional independent variable to a multiple regression on the dependent variable while adjusting for the effect of the other independent variables already in the model. They are calculated by:

1.  Computing the residuals of regressing the response variable against the independent variables but omitting $X_i$
2.  Computing the residuals from regressing $X_i$ against the remaining independent variables
3.  Plotting the residuals from (1) against the residuals from (2).

By regressing $\epsilon(Y|X_1)$ on $\epsilon(X_2|X_1)$ we can see if $X_2$ contributes any further explanation of $Y$ that isn't already explained by $X_1$. This may seem like it would be tedious to generate all of the residuals from all of these regressions, but luckily there is a function to automate the process, the avPlots() function from the car package [@car]. This function will produce a matrix of added-variable plots that aren't publication quality, but that are useful for diagnostics and variable interpretation (@fig-addedVariables).

```{r }
#| label: fig-addedVariables
#| fig.cap: "Added-variable plots for the full model."

avPlots(full.mod)

```

For diagnostics, the added-variable plots help us identify influential observations associated with a particular variable that may not be obvious when viewing the residuals for all independent variables being considered at the same time. Note that in the plots for our full model (@fig-addedVariables), the plot for our significant variable, `lat`, identifies observation 1 as being an influential observation, but in the diagnostic plots for the overall model, it isn't flagged. The added-variable plots can also identify the appropriate functional form of the regression in the same way that scatter plots help us with simple linear regression.

For interpretation, these plots provide a fast, visual assessment of the effect of each variable in the multiple regression. Note that for our full model, the added-variable plot for `lat` appears to have the most obvious slope, and results in the only significant hypothesis test of the partial regression coefficients.

# Solutions to multicollinearity

## Do nothing

If our purpose for the multiple regression is simply to produce a predictive model for our response variable, and we aren't worried about the effect of individual predictor variables, then multicollinearity isn't a problem.

## Change the model

If two predictor variables are very strongly collinear, it means that they are both likely to predict the same amount of variation in our response variable, so removing one of them from the model may provide a solution. You may use your knowledge of the system you're working in to choose the variable to remove, or a cost analysis (which would be the most expensive to measure in future studies), or statistical model selection criteria (see Box 6.8 & Table 6.4 in @Quinn.Keough2002). The currently preferred model selection approach appears to be Akaike's Information Criterion[^4] (AIC), though some prefer Schwarz's Bayesian Information Criterion[^5] (BIC) [@johnson2004].

```{r }
#| label: tbl-ICs
#| tbl-cap: "Model selection criteria for the full model and with collinear predictor variables removed."

mod.drop.long <- lm(log10(c3 + 0.1) ~ lat + map + mat + jjamap + djfmap, 
                    data = df)
mod.drop.djmap <- lm(log10(c3 + 0.1) ~ lat + long + map + mat + jjamap, 
                     data = df)
sel1 <- AIC(full.mod,mod.drop.long,mod.drop.djmap)
sel2 <- BIC(full.mod,mod.drop.long,mod.drop.djmap)

tab <- data.frame(cbind(sel1,sel2[,2]))
names(tab) <- c("df", "AIC", "BIC")
row.names(tab) <- c("full model", "long dropped", "djmap dropped")

tab <- rownames_to_column(tab, var = "Model")

ICs <- kbl(
  tab,
  digits = 2
  ) |>
  kable_classic(full = FALSE)

ICs

```

If we focus on the two variables with VIF \> 5, we see that dropping longitude produces the model with the least amount of information lost (@tbl-ICs). Based on AIC (or BIC) values for our variables, we should choose the reduced model that excludes longitude (@tbl-reducedMod).

```{r }
#| label: tbl-reducedMod
#| tbl-cap: "Regression summary and VIF for the reduced model (longitude removed)."

tab <- data.frame(
  cbind(
    summary(mod.drop.long)$coefficients,
    append(vif(mod.drop.long), values = NA, after = 0) 
    )
  ) 

tab <- rownames_to_column(tab, var = "Variable")

tab$Pr...t.. <- ifelse(tab$Pr...t.. < 0.001, "< 0.001", 
                       format(
                         round(
                           tab$Pr...t..,
                           digits = 3
                           ),
                         nsmall = 3
                         )
                       )

reducedMod <- kbl(
  tab,
  col.names = c(
    " ",
    "$\\hat{\\beta}$",
    "SE",
    "t-statistic",
    "P-value",
    "VIF"
  ),
  digits = c(0, 2, 2, 2, 0, 1),
  align = "lrrrrr"
  ) |>
  kable_classic(full = FALSE)

reducedMod  
  
```

The VIF values for this reduced model are all smaller than 5 and the model's adjusted $r^2=$ `r round(summary(mod.drop.long)$adj.r.squared, 3)` is slightly better than that for our full model. Is this the best approach? I would argue that knowledge of the system should be used when possible.

In their original publication, @Paruelo.Lauenroth1996 chose to use two separate analyses. The first focusing on location and the second on mean annual precipitation patterns. Their two models were:

<!-- Here I'm introducing a way to write multiple equations in LaTeX that    -->

<!-- use an alignment symbol, "&" and that label the equations, resulting in -->

<!-- them being numbered in the output.                                      -->

```{=tex}
\begin{align}
log_{10}(C_3 + 0.1) &= \beta_0 + \beta_1(lat) + \beta_2(long) + \beta_3(lat \times long) + \epsilon (\#eq:PLModel1) \\
\\
log_{10}(C_3 + 0.1) &= \beta_0 + \beta_1(MAP) + \beta_2(MAT) + \beta_3(JJAMAP) + \beta_4(DJFMAP) + \epsilon (\#eq:PLModel2) \\
\end{align}
```
## Standardize (Center) the Variables

In this example, let's focus on the first model, with latitude, longitude and the interaction of latitude and longitude. Unsurprisingly, they found extreme collinearity between latitude, longitude, and the interaction (@tbl-PLModel1taba).

```{r }
#| label: PLModel_1syntax
#| echo: TRUE

# In this code chunk, I'm demonstrating a bit of R formula code, and that
# interactions are simply variables multiplied together.

# All three of the following models do exactly the same analysis. The models a &
# b differ only in the formula syntax: "*" in R means that you include all main
# effects and interactions of the variables on either side of the symbol.

# Model c uses a new computed variable that is the product of latitude and
# longitude for each observation. The last bit of R code demonstrated is that if
# you put () around a function call, it tell R to print out the result.

(PLModel1a <- lm(log10(c3+0.1) ~ lat + long + lat:long, data = df))

(PLModel1b <- lm(log10(c3+0.1) ~ lat * long, data = df))

df$latlong <- df$lat * df$long
(PLModel1c <- lm(log10(c3+0.1) ~ lat + long + latlong, data = df))

```

```{r }
#| label: tbl-PLModel1taba
#| tbl-cap: "Regression summary and VIF for the @Paruelo.Lauenroth1996 model that focused on location."

tab <- data.frame(
  cbind(
    summary(PLModel1a)$coefficients,
    append(vif(PLModel1a), values = NA, after = 0) 
    )
  ) 

tab <- rownames_to_column(tab, var = "Variable")

tab$Pr...t.. <- ifelse(tab$Pr...t.. < 0.001, "< 0.001", 
                       format(
                         round(
                           tab$Pr...t..,
                           digits = 3
                           ),
                         nsmall = 3
                         )
                       )

PLModel1taba <- kbl(
  tab,
  col.names = c(
    " ",
    "$\\hat{\\beta}$",
    "SE",
    "t-statistic",
    "P-value",
    "VIF"
  ),
  digits = c(0, 2, 2, 2, 0, 1),
  align = "lrrrrr"
  ) |>
  kable_classic(full = FALSE)

PLModel1taba  

```

One approach to "fixing" collinearity, particularly when one of the variables is a computation involving one or more of the other variables of interest (all interactions), is to center the data. We can do this by subtracting the means from each observation. I've used the scale() function [@base], which can be used to scale (divide by the standard deviation) and center (subtracting the means) to create new variables that represent the centered values for latitude (`latc`) and longitude (`longc`).

```{r }
#| label: centPLModel1

df$latc <- scale(
  df$lat, 
  center = TRUE, 
  scale = FALSE
  )

df$longc <- scale(
  df$long, 
  center = TRUE, 
  scale = FALSE
  )

centPLModel1 <- lm(log10(c3 + 0.1) ~ latc + longc + latc:longc, data = df)

```

After centering the data, the VIF values are all \< 2 (@tbl-centPLModel1out) and the diagnostic plots for this new model (@fig-centPLModel1) look fine.

```{r }
#| label: tbl-centPLModel1out
#| tbl-cap: "Regression summary and VIF for the @Paruelo.Lauenroth1996 model that focused on location, after centering the data."


tab <- data.frame(
  cbind(
    summary(centPLModel1)$coefficients,
    append(vif(centPLModel1), values = NA, after = 0) 
    )
  ) 

tab <- rownames_to_column(tab, var = "Variable")

tab$Pr...t.. <- ifelse(tab$Pr...t.. < 0.001, "< 0.001", 
                       format(
                         round(
                           tab$Pr...t..,
                           digits = 3
                           ),
                         nsmall = 3
                         )
                       )

centPLModel1tab <- kbl(
  tab,
  col.names = c(
    " ",
    "$\\hat{\\beta}$",
    "SE",
    "t-statistic",
    "P-value",
    "VIF"
  ),
  digits = c(0, 4, 4, 2, 0, 1),
  align = "lrrrrr"
  ) |>
  kable_classic(full = FALSE)

centPLModel1tab  
```

```{r}
#| label: fig-centPLModel1
#| fig.cap: "Diagnostic plots for the the @Paruelo.Lauenroth1996 model that focused on location, after centering the data."

autoplot(centPLModel1)
```

I would decide to reject the null hypothesis of no interaction between latitude and longitude effect on the relative abundance of C3 plants (@tbl-centPLModel1out). My interpretation for this model would be that even though the partial regression coefficient for longitude wasn't significant, the effect of latitude, which was significant, depended on the value of longitude and cannot be interpreted independently.

Interpreting significant 2-way interactions is usually straightforward given your knowledge of the system you're working in, but higher level interactions (e.g. 3-way, 4-way, etc.) may be difficult to impossible.

## Partial Least Squares Regression (PLSR) and Principle Component Regression (PCR)

Both PLSR and PCR find linear regressions based on projections of the original predictor and response variables to new spaces where the combinations of the predictor variables are independent. We'll talk about principle components later in the semester, but for now this approach is beyond the scope of this class. If you want learn more about these approaches, check out the pls package [@pls].

# References:

[^1]: I used `tolower()` with this data frame to edit the all-caps variable names to all-lower.

[^2]: Note that centesimal degrees are ***not*** the same as decimal degrees. In the centesimal system, a right angle is divided into 100 centesimal degrees; each centesimal degree, into 100 centesimal minutes; and each centesimal minute into 100 centesimal seconds. (Centesimal degrees are also known as grads, grades, or gon.)

[^3]: We can use the vif() function from the car package [@car] to calculate VIF.

[^4]: AIC is an estimate of the expected Kullback--Leibler information lost by using a model to approximate the process that generated observed data. AIC values are relative, so given a set of models, the one with the minimum AIC is the preferred model.

[^5]: BIC is a model selection criterion designed to find the most probable model (from a Bayesian perspective) given the data. As with AIC, BIC values are relative, so given a set of models, the one with the minimum BIC is the preferred model.
